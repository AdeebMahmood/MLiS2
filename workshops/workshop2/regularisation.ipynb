{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regularisation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNY5muSvCTR9hBqjmC4yroc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adammoss/MLiS2/blob/master/workshops/workshop2/regularisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9lgu7n44eFs",
        "colab_type": "text"
      },
      "source": [
        "**Regularisation**\n",
        "\n",
        "In this example you are given a dataset (MNIST) with a limited number of training examples (only 1000 compared to the usual 60,000). \n",
        "\n",
        "Your goal is to implement regularisation methods to achive the **lowest possible test loss using this dataset**. \n",
        "\n",
        "You should consider methods given in the lectures including:\n",
        "\n",
        "*   Data augmentation\n",
        "*   Early stopping\n",
        "*   L1/L2 penalty norms\n",
        "*   Dropout\n",
        "\n",
        "You are free to change the network architecture and model complexity, but the main purpose of the workshop is to investigate regularisation (next week you will look at CNN architectures in detail). \n",
        "\n",
        "You are also free to change the choice of optimiser, and other hyper-parameters such as the batch size.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNviuTwum6vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARZRYjHQnE-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I-MxTxAnH2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxO576eJnMXN",
        "colab_type": "code",
        "outputId": "2ae932e1-c8f9-4bf8-cff6-00f5d3cd4fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4F_HTQpnvSk",
        "colab_type": "text"
      },
      "source": [
        "First load the MNIST dataset and add a channels dimension (channels last convention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twdc-t9FnN_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train[..., tf.newaxis].astype(np.float32)\n",
        "x_test = x_test[..., tf.newaxis].astype(np.float32)\n",
        "\n",
        "img_rows = x_train.shape[1]\n",
        "img_cols = x_train.shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEsWYkNz5Po7",
        "colab_type": "text"
      },
      "source": [
        "Let's use a much smaller training dataset of 1000 examples so overfitting is more problematic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzt-HoIo4yks",
        "colab_type": "code",
        "outputId": "b75502e7-f907-4112-a9b6-46046b339e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "n_train = 1000\n",
        "x_train = x_train[0:n_train, :]\n",
        "y_train = y_train[0:n_train]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2JSWYGKjsPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(15, 15))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(np.squeeze(img))\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDfQh4AfoBAH",
        "colab_type": "text"
      },
      "source": [
        "Let's visualise several training examples - to do this we use the keras ImageDataGenerator. We rescale images by 1/255 to normalise them in the range (0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuOz9BopjZPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zp2bQaMjdTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_gen = image_generator.flow(x_train, y_train, batch_size=32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhg1Unx-kTu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_images, sample_labels = next(data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL_Jp9JZklCb",
        "colab_type": "code",
        "outputId": "0312609e-bbb0-4c55-80d9-4c9ae67a1e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "plotImages(sample_images[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAADZCAYAAADWkMBPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAgOwpMAAAAIDs/R/3+Lq+cBrWOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x1080 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8bStvJVoVlj",
        "colab_type": "text"
      },
      "source": [
        "One regularisation method to deal with over-fitting is data augmentation. The image generator can apply various transformations to data - here we apply a random rotation of upto 45 degrees and visualise the same training example with different augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz28zlncmIiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_generator = ImageDataGenerator(rescale=1./255, \n",
        "                                     rotation_range=20) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc740vywmSGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_gen = image_generator.flow(x_train, y_train, batch_size=32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Ephs1Sjh5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_images = [data_gen[0][0][0] for i in range(5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLIqL9maj2No",
        "colab_type": "code",
        "outputId": "841c8253-d930-4532-fd87-2152fae705e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "plotImages(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAADZCAYAAADWkMBPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngAEAAAAU7/8CThZWdGJC6IwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIE6-wlA3J4h",
        "colab_type": "text"
      },
      "source": [
        "Define a basic CNN with 32 convolutional filters using a 3x3 kernel, followed by a dense fully connected layer of 128 units and an output layer of 10 units with softmax activation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKolHZQUL8-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicCNN(Model):\n",
        "  def __init__(self):\n",
        "    super(BasicCNN, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuhNDi134B2G",
        "colab_type": "text"
      },
      "source": [
        "Main training routine - uses the more detailed Gradient Tape API to iterate over the dataset and update the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZH8jdqKohiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainer(cls, train_image_generator, verbose=False, batch_size=32, \n",
        "            max_epochs=5):\n",
        "  \n",
        "  model = cls()\n",
        "\n",
        "  train_data_gen = train_image_generator.flow(x_train, y_train, \n",
        "                                              batch_size=batch_size) \n",
        "\n",
        "  test_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "  test_data_gen = test_image_generator.flow(x_test, y_test, \n",
        "                                              batch_size=batch_size) \n",
        "\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='train_accuracy')\n",
        "\n",
        "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='test_accuracy')\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = model(images, training=True)\n",
        "      loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "  @tf.function\n",
        "  def test_step(images, labels):\n",
        "    predictions = model(images, training=False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    # Reset the metrics at the start of the next epoch\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "    batches = 0\n",
        "    for images, labels in train_data_gen:\n",
        "      train_step(images, labels)\n",
        "      batches += 1\n",
        "      if batches >= len(x_train) / batch_size:\n",
        "        break\n",
        "\n",
        "    batches = 0\n",
        "    for images, labels in test_data_gen:\n",
        "      test_step(images, labels)\n",
        "      batches += 1\n",
        "      if batches >= len(x_test) / batch_size:\n",
        "        break\n",
        "\n",
        "    if verbose:\n",
        "      template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "      print(template.format(epoch+1,\n",
        "                            train_loss.result(),\n",
        "                            train_accuracy.result()*100,\n",
        "                            test_loss.result(),\n",
        "                            test_accuracy.result()*100))\n",
        "    \n",
        "  return test_accuracy.result().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkemC6SvTLOH",
        "colab_type": "code",
        "outputId": "0294a553-ca6a-4404-8faf-f8ae8b8c36ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "trainer(BasicCNN, train_image_generator, verbose=True, max_epochs=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.9146898984909058, Accuracy: 70.9000015258789, Test Loss: 0.5571092367172241, Test Accuracy: 82.86000061035156\n",
            "Epoch 2, Loss: 0.2783726751804352, Accuracy: 90.5999984741211, Test Loss: 0.48854824900627136, Test Accuracy: 84.63999938964844\n",
            "Epoch 3, Loss: 0.13073086738586426, Accuracy: 96.30000305175781, Test Loss: 0.4192239046096802, Test Accuracy: 87.02999877929688\n",
            "Epoch 4, Loss: 0.0654975175857544, Accuracy: 98.9000015258789, Test Loss: 0.4050845801830292, Test Accuracy: 88.12000274658203\n",
            "Epoch 5, Loss: 0.036454491317272186, Accuracy: 99.19999694824219, Test Loss: 0.4177667200565338, Test Accuracy: 88.61000061035156\n",
            "Epoch 6, Loss: 0.014827845618128777, Accuracy: 100.0, Test Loss: 0.4191325604915619, Test Accuracy: 89.06000518798828\n",
            "Epoch 7, Loss: 0.007034609094262123, Accuracy: 100.0, Test Loss: 0.42711856961250305, Test Accuracy: 89.37000274658203\n",
            "Epoch 8, Loss: 0.004002350848168135, Accuracy: 100.0, Test Loss: 0.43342989683151245, Test Accuracy: 89.30000305175781\n",
            "Epoch 9, Loss: 0.002993944799527526, Accuracy: 100.0, Test Loss: 0.45029416680336, Test Accuracy: 89.47000122070312\n",
            "Epoch 10, Loss: 0.0022667658049613237, Accuracy: 100.0, Test Loss: 0.4531206488609314, Test Accuracy: 89.55000305175781\n",
            "Epoch 11, Loss: 0.001779924496077001, Accuracy: 100.0, Test Loss: 0.45856043696403503, Test Accuracy: 89.58000183105469\n",
            "Epoch 12, Loss: 0.0014572973595932126, Accuracy: 100.0, Test Loss: 0.4643591344356537, Test Accuracy: 89.61000061035156\n",
            "Epoch 13, Loss: 0.001252001035027206, Accuracy: 100.0, Test Loss: 0.4745675325393677, Test Accuracy: 89.56999969482422\n",
            "Epoch 14, Loss: 0.001064030104316771, Accuracy: 100.0, Test Loss: 0.47320792078971863, Test Accuracy: 89.67000579833984\n",
            "Epoch 15, Loss: 0.0009695847402326763, Accuracy: 100.0, Test Loss: 0.4773784875869751, Test Accuracy: 89.68000030517578\n",
            "Epoch 16, Loss: 0.0008333338191732764, Accuracy: 100.0, Test Loss: 0.48562705516815186, Test Accuracy: 89.6300048828125\n",
            "Epoch 17, Loss: 0.0007577407523058355, Accuracy: 100.0, Test Loss: 0.49060091376304626, Test Accuracy: 89.63999938964844\n",
            "Epoch 18, Loss: 0.0006946095381863415, Accuracy: 100.0, Test Loss: 0.4934650957584381, Test Accuracy: 89.66000366210938\n",
            "Epoch 19, Loss: 0.0006380878039635718, Accuracy: 100.0, Test Loss: 0.49450743198394775, Test Accuracy: 89.68000030517578\n",
            "Epoch 20, Loss: 0.0005675649153999984, Accuracy: 100.0, Test Loss: 0.5032588243484497, Test Accuracy: 89.63999938964844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    }
  ]
}