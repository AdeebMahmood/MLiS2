{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regularisation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPTtwfOKTP/OJpUGj7Cwxp6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adammoss/MLiS2/blob/master/workshops/workshop2/regularisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9lgu7n44eFs",
        "colab_type": "text"
      },
      "source": [
        "**Regularisation**\n",
        "\n",
        "In this example you are given a dataset (MNIST) with a limited number of training examples (only 1000 compared to the usual 60,000). \n",
        "\n",
        "Your goal is to implement regularisation methods to achive the **lowest possible test loss using this dataset**. \n",
        "\n",
        "You should consider methods given in the lectures including:\n",
        "\n",
        "*   Data augmentation\n",
        "*   Early stopping\n",
        "*   L1/L2 penalty norms\n",
        "*   Dropout\n",
        "\n",
        "You are free to change the network architecture and model complexity, but the main purpose of the workshop is to investigate regularisation (next week you will look at CNN architectures in detail). \n",
        "\n",
        "You are also free to change the choice of optimiser, and other hyper-parameters such as the batch size.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNviuTwum6vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARZRYjHQnE-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I-MxTxAnH2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxO576eJnMXN",
        "colab_type": "code",
        "outputId": "08dce834-7edc-4c9b-e468-f6204395caa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4F_HTQpnvSk",
        "colab_type": "text"
      },
      "source": [
        "First load the MNIST dataset and add a channels dimension (channels last convention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twdc-t9FnN_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train[..., tf.newaxis].astype(np.float32)\n",
        "x_test = x_test[..., tf.newaxis].astype(np.float32)\n",
        "\n",
        "img_rows = x_train.shape[1]\n",
        "img_cols = x_train.shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEsWYkNz5Po7",
        "colab_type": "text"
      },
      "source": [
        "Let's use a much smaller training dataset of 1000 examples so overfitting is more problematic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzt-HoIo4yks",
        "colab_type": "code",
        "outputId": "593e4008-119d-4045-ade6-1d9b31c5fd32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "n_train = 1000\n",
        "x_train = x_train[0:n_train, :]\n",
        "y_train = y_train[0:n_train]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2JSWYGKjsPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(15, 15))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(np.squeeze(img))\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDfQh4AfoBAH",
        "colab_type": "text"
      },
      "source": [
        "Let's visualise several training examples - to do this we use the keras ImageDataGenerator. We rescale images by 1/255 to normalise them in the range (0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuOz9BopjZPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "c1ef21c3-a853-4b49-ec1a-3acc127ac52f"
      },
      "source": [
        "image_generator = ImageDataGenerator(rescale=1./255) \n",
        "data_gen = image_generator.flow(x_train, y_train, batch_size=32) \n",
        "sample_images, sample_labels = next(data_gen)\n",
        "plotImages(sample_images[:5])"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAADZCAYAAADWkMBPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x1080 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8bStvJVoVlj",
        "colab_type": "text"
      },
      "source": [
        "One regularisation method to deal with over-fitting is data augmentation. The image generator can apply various transformations to data - here we apply a random rotation of upto 20 degrees and visualise the same training example with different augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz28zlncmIiP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "edfb3340-5f1d-4470-e38e-6cd432da6b1a"
      },
      "source": [
        "image_generator = ImageDataGenerator(rescale=1./255, \n",
        "                                     rotation_range=20) \n",
        "data_gen = image_generator.flow(x_train, y_train, batch_size=32) \n",
        "augmented_images = [data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAADZCAYAAADWkMBPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x1080 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIE6-wlA3J4h",
        "colab_type": "text"
      },
      "source": [
        "Define a basic CNN with 32 convolutional filters using a 3x3 kernel, followed by a dense fully connected layer of 128 units and an output layer of 10 units with softmax activation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKolHZQUL8-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicCNN(Model):\n",
        "  def __init__(self):\n",
        "    super(BasicCNN, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuhNDi134B2G",
        "colab_type": "text"
      },
      "source": [
        "Main training routine - uses the more detailed Gradient Tape API to iterate over the dataset and update the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZH8jdqKohiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainer(cls, train_image_generator, test_image_generator, \n",
        "            verbose=False, batch_size=32, max_epochs=5):\n",
        "  \n",
        "  model = cls()\n",
        "\n",
        "  train_data_gen = train_image_generator.flow(x_train, y_train, \n",
        "                                              batch_size=batch_size) \n",
        "\n",
        "  test_data_gen = test_image_generator.flow(x_test, y_test, \n",
        "                                              batch_size=batch_size) \n",
        "\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='train_accuracy')\n",
        "\n",
        "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='test_accuracy')\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = model(images, training=True)\n",
        "      loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "  @tf.function\n",
        "  def test_step(images, labels):\n",
        "    predictions = model(images, training=False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    # Reset the metrics at the start of the next epoch\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "    batches = 0\n",
        "    for images, labels in train_data_gen:\n",
        "      train_step(images, labels)\n",
        "      batches += 1\n",
        "      if batches >= len(x_train) / batch_size:\n",
        "        break\n",
        "\n",
        "    batches = 0\n",
        "    for images, labels in test_data_gen:\n",
        "      test_step(images, labels)\n",
        "      batches += 1\n",
        "      if batches >= len(x_test) / batch_size:\n",
        "        break\n",
        "\n",
        "    if verbose:\n",
        "      template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "      print(template.format(epoch+1,\n",
        "                            train_loss.result(),\n",
        "                            train_accuracy.result()*100,\n",
        "                            test_loss.result(),\n",
        "                            test_accuracy.result()*100))\n",
        "    \n",
        "  return test_loss.result().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBSBEZftgDsL",
        "colab_type": "text"
      },
      "source": [
        "Baseline run with no regularisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkemC6SvTLOH",
        "colab_type": "code",
        "outputId": "c5abbf24-e9bd-47c4-cfb1-eed8f7736641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "test_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "final_test_loss = trainer(BasicCNN, train_image_generator, test_image_generator, \n",
        "                          verbose=True, max_epochs=20)\n",
        "print('Final test loss:', final_test_loss)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.85606849193573, Accuracy: 73.19999694824219, Test Loss: 0.5028987526893616, Test Accuracy: 83.84000396728516\n",
            "Epoch 2, Loss: 0.29988542199134827, Accuracy: 91.19999694824219, Test Loss: 0.4548865258693695, Test Accuracy: 85.63999938964844\n",
            "Epoch 3, Loss: 0.17753031849861145, Accuracy: 95.70000457763672, Test Loss: 0.41680246591567993, Test Accuracy: 87.36000061035156\n",
            "Epoch 4, Loss: 0.0794360488653183, Accuracy: 97.79999542236328, Test Loss: 0.3993152379989624, Test Accuracy: 88.27999877929688\n",
            "Epoch 5, Loss: 0.030408350750803947, Accuracy: 99.5999984741211, Test Loss: 0.42995426058769226, Test Accuracy: 88.0\n",
            "Epoch 6, Loss: 0.012128583155572414, Accuracy: 100.0, Test Loss: 0.41340842843055725, Test Accuracy: 88.87000274658203\n",
            "Epoch 7, Loss: 0.006200607866048813, Accuracy: 100.0, Test Loss: 0.41759946942329407, Test Accuracy: 89.27999877929688\n",
            "Epoch 8, Loss: 0.003910799510776997, Accuracy: 100.0, Test Loss: 0.43225908279418945, Test Accuracy: 89.27999877929688\n",
            "Epoch 9, Loss: 0.0028652071487158537, Accuracy: 100.0, Test Loss: 0.4378543794155121, Test Accuracy: 89.37000274658203\n",
            "Epoch 10, Loss: 0.0022896560840308666, Accuracy: 100.0, Test Loss: 0.4444579482078552, Test Accuracy: 89.43000030517578\n",
            "Epoch 11, Loss: 0.0018146024085581303, Accuracy: 100.0, Test Loss: 0.4547627568244934, Test Accuracy: 89.55000305175781\n",
            "Epoch 12, Loss: 0.0015604658983647823, Accuracy: 100.0, Test Loss: 0.4562346637248993, Test Accuracy: 89.45000457763672\n",
            "Epoch 13, Loss: 0.0013274080120027065, Accuracy: 100.0, Test Loss: 0.4653080403804779, Test Accuracy: 89.56000518798828\n",
            "Epoch 14, Loss: 0.0011727212695404887, Accuracy: 100.0, Test Loss: 0.46630391478538513, Test Accuracy: 89.56999969482422\n",
            "Epoch 15, Loss: 0.0010103525128215551, Accuracy: 100.0, Test Loss: 0.4745829999446869, Test Accuracy: 89.58000183105469\n",
            "Epoch 16, Loss: 0.0009017902193590999, Accuracy: 100.0, Test Loss: 0.475532203912735, Test Accuracy: 89.70999908447266\n",
            "Epoch 17, Loss: 0.0007977980421856046, Accuracy: 100.0, Test Loss: 0.47889846563339233, Test Accuracy: 89.67000579833984\n",
            "Epoch 18, Loss: 0.0007287012413144112, Accuracy: 100.0, Test Loss: 0.48447465896606445, Test Accuracy: 89.66000366210938\n",
            "Epoch 19, Loss: 0.0006473184330388904, Accuracy: 100.0, Test Loss: 0.488246351480484, Test Accuracy: 89.69000244140625\n",
            "Epoch 20, Loss: 0.0005834588664583862, Accuracy: 100.0, Test Loss: 0.491299569606781, Test Accuracy: 89.72000122070312\n",
            "Final test loss: 0.49129957\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}