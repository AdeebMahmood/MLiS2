{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workshop1_question4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMX3xRQvR+45R3jfUC15X+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adammoss/MLiS2/blob/master/workshops/workshop1/workshop1_question4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tbHMKVAmIkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1GtAJWGmPZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0_VlZPamRNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "235b0a1e-6c49-4149-b359-e783c35f97a2"
      },
      "source": [
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "print(X)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNgXlZK1mS4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8d5ff273-ae0d-46f0-a426-e6242f9552c4"
      },
      "source": [
        "Y = np.array([[0], [1], [1], [0]])\n",
        "print(Y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdufl_ArmUdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    # Initialise with random weights\n",
        "    self.weights_1 = 0.1 * np.random.normal(size=(3,2))\n",
        "    self.weights_2 = 0.1 * np.random.normal(size=(3,2))\n",
        "    self.weights_3 = 0.1 * np.random.normal(size=(3,1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Do a forward pass\n",
        "    if len(x.shape) == 1:\n",
        "      # Single example, so add a batch dimension of 1\n",
        "      x = np.expand_dims(x, axis=0)\n",
        "    # First hidden layer \n",
        "    z_1 = np.matmul(np.hstack((np.ones(shape=(x.shape[0], 1)), x)), self.weights_1)\n",
        "    # Apply ReLU activation function\n",
        "    a_1 = np.maximum(z_1, 0)\n",
        "    # Second hidden layer \n",
        "    z_2 = np.matmul(np.hstack((np.ones(shape=(a_1.shape[0], 1)), a_1)), self.weights_2)\n",
        "    # Apply ReLU activation function\n",
        "    a_2 = np.maximum(z_2, 0)\n",
        "    # Output layer\n",
        "    z_3 = np.matmul(np.hstack((np.ones(shape=(a_2.shape[0], 1)), a_2)), self.weights_3)\n",
        "    # Linear activation \n",
        "    a_3 = z_3\n",
        "    return z_1, a_1, z_2, a_2, z_3, a_3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8nJVTAEmp17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 1\n",
        "learning_rate = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI1drvnJmsdD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "775c0928-6848-41f6-c23e-d1b9f7284f84"
      },
      "source": [
        "m = MLP()\n",
        "loss_history = []\n",
        "weights_1_history = []\n",
        "weights_2_history = []\n",
        "for epoch in range(num_epochs):\n",
        "  # Do forward pass\n",
        "  z_1, a_1, z_2, a_2, z_3, a_3 = m.forward(X)\n",
        "  loss = 0.25 * np.sum((a_2 - Y)**2)\n",
        "  loss_history.append(loss)\n",
        "  if epoch % 100 == 0:\n",
        "    print(epoch, loss)\n",
        "  # Delta_2 has shape(4, 1), the first dimension being the batch dimension\n",
        "  delta_3 = 0.5 * ( a_3 - Y)\n",
        "  g_prime_2 = np.heaviside(z_2, 0)\n",
        "  # Delta_2 has shape (4, 2)\n",
        "  delta_2 = np.matmul(delta_3, m.weights_3[1:3, :].T) * g_prime_2\n",
        "  g_prime_1 = np.heaviside(z_1, 0)\n",
        "  # Delta_1 has shape (4, 2)\n",
        "  delta_1 = np.matmul(delta_2, m.weights_2[1:3, :].T) * g_prime_1\n",
        "  m.weights_1[0, :] -= learning_rate * np.sum(delta_1[:, :], axis=0)\n",
        "  m.weights_1[1:3, :] -= learning_rate * np.matmul(X.T, delta_1)\n",
        "  m.weights_2[0, :] -= learning_rate * np.sum(delta_2[:, :], axis=0)\n",
        "  m.weights_2[1:3, :] -= learning_rate * np.matmul(a_2.T, delta_2)\n",
        "  m.weights_3[0, :] -= learning_rate * np.sum(delta_3[:, :], axis=0)\n",
        "  m.weights_3[1:3, :] -= learning_rate * np.matmul(a_3.T, delta_3)\n",
        "  weights_1_history.append(np.copy(m.weights_1))\n",
        "  weights_2_history.append(np.copy(m.weights_2))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.9214618834718462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p1Wgxalm2eE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}