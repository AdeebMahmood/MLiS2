{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4yJ8SJr88eCpZbb6123Ck",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adammoss/MLiS2/blob/master/workshops/workshop5/rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeUfbxv9ghmQ",
        "colab_type": "text"
      },
      "source": [
        "As an example application, let's build a language model that predicts the probability of a sentence of $\\tau$ words,\n",
        "\n",
        "$\n",
        "P \\left( \\boldsymbol{x}^{(1)}, \\boldsymbol{x}^{(2)}, \\ldots, \\boldsymbol{x}^{(\\tau)}    \\right) = \\prod_{t  = 1}^{\\tau} P \\left( \\boldsymbol{x}^{(i)} |  \\boldsymbol{x}^{(1)}, \\ldots, \\boldsymbol{x}^{(i-1)}    \\right) \n",
        "$\n",
        "\n",
        "where $\\boldsymbol{x}^{(t)}$ is a vector representing a word. For now, we will use one-hot encoding where the length of the word vector is equal to the vocabulary size. This means that all words are orthogonal to one another. \n",
        "\n",
        "We train the model by setting the targets to be equal to the inputs, shifted by one time-step, i.e. $\\boldsymbol{y}^{(t)} = \\boldsymbol{x}^{(t-1)}$. Once the model is trained, we can use the network to output the probability of the next word, given an input sequence. The model is  generative as it can be used to produce new outputs, conditional on its previous inputs. \n",
        "\n",
        "For this example we extract sentences from Internet Movie Database (IMDB) reviews. We use the Natural Language Toolkit (NLTK) to tokenise sentences into words. For each sentence, we add an additional token to the beginning and end of sentences to indicate where they start and stop.  To reduce the  training time, we restrict the vocabulary to the 1000 most common words, replacing all others by an unknown token. We also truncate sentences to a maximum of 10 words, and use a limited training set of 1000 sentences. Even so, training is slow, as we forward and back-propagate single training examples at a time. \n",
        "\n",
        "The sentence tokenisation is based on that in https://github.com/dennybritz/rnn-tutorial-rnnlm. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alq1W_bCWoTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import itertools\n",
        "import operator\n",
        "import numpy as np\n",
        "import nltk\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMEPKb6en40I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1Byt39K3Dua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhl7G_SQ7wlH",
        "colab_type": "text"
      },
      "source": [
        "Download NLTK data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRyc8euxWpzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "nltk.download(\"book\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBvLWBQt8EZ6",
        "colab_type": "text"
      },
      "source": [
        "Upload imdb_sentences.txt file (or another file containing a list of sentences if you wish)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfpGBFRj-DzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('imdb_sentences.txt'):\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHNYmTqB93G9",
        "colab_type": "text"
      },
      "source": [
        "Add sentence start and end tags, convert to lower case and strip newlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyBM3rWv9chG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_start_token = \"SENTENCE_START\"\n",
        "sentence_end_token = \"SENTENCE_END\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8QVY1IkAYEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('imdb_sentences.txt', 'r') as f:\n",
        "  sentences = f.readlines()\n",
        "sentences = [\"%s %s %s\" % (sentence_start_token, x.lstrip().rstrip('.\\n').lower(), sentence_end_token) for x in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPIWW5lqtSLG",
        "colab_type": "code",
        "outputId": "526654d7-5d1d-4833-9428-15e691ba929a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "print(\"Parsed %d sentences.\" % (len(sentences)))\n",
        "for i in range(0, 10):\n",
        "  print(\"Example: %s\" % sentences[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsed 12188 sentences.\n",
            "Example: SENTENCE_START story of a man who has unnatural feelings for a pig SENTENCE_END\n",
            "Example: SENTENCE_START starts out with a opening scene that is a terrific example of absurd comedy SENTENCE_END\n",
            "Example: SENTENCE_START a formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers SENTENCE_END\n",
            "Example: SENTENCE_START unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting SENTENCE_END\n",
            "Example: SENTENCE_START even those from the era should be turned off SENTENCE_END\n",
            "Example: SENTENCE_START the cryptic dialogue would make shakespeare seem easy to a third grader SENTENCE_END\n",
            "Example: SENTENCE_START on a technical level it's better than you might think with some good cinematography by future great vilmos zsigmond SENTENCE_END\n",
            "Example: SENTENCE_START future stars sally kirkland and frederic forrest can be seen briefly SENTENCE_END\n",
            "Example: SENTENCE_START airport '77 starts as a brand new luxury 747 plane is loaded up with valuable paintings & such belonging to rich businessman philip stevens (james stewart) who is flying them & a bunch of vip's to his estate in preparation of it being opened to the public as a museum, also on board is stevens daughter julie (kathleen quinlan) & her son SENTENCE_END\n",
            "Example: SENTENCE_START the luxury jetliner takes off as planned but mid-air the plane is hi-jacked by the co-pilot chambers (robert foxworth) & his two accomplice's banker (monte markham) & wilson (michael pataki) who knock the passengers & crew out with sleeping gas, they plan to steal the valuable cargo & land on a disused plane strip on an isolated island but while making his descent chambers almost hits an oil rig in the ocean & loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the bermuda triangle SENTENCE_END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTBDO_fs-udT",
        "colab_type": "text"
      },
      "source": [
        "Tokenize the sentences into words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRfoIQZV-tNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDJ1NGJy-7i_",
        "colab_type": "code",
        "outputId": "27c7fb55-47e6-499a-9e80-11980ab56dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
        "print(\"Found %d unique words tokens.\" % len(word_freq.items()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 18154 unique words tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZGpHm2s_IyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 1000\n",
        "unknown_token = 'UNKNOWN_TOKEN'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBTJmo8G_Fv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = word_freq.most_common(vocab_size-1)\n",
        "index_to_word = [x[0] for x in vocab]\n",
        "index_to_word.append(unknown_token)\n",
        "word_to_index = dict([(w,i) for i, w in enumerate(index_to_word)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-C-wm5h_kQB",
        "colab_type": "text"
      },
      "source": [
        "Replace all words not in our vocabulary with the unknown token and discard sentences under min / over max number of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS0xWviykoTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_sentence_length = 5\n",
        "truncate_sentence_length = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXT2EKyw_h6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "purged_sentences = []\n",
        "for i, sent in enumerate(tokenized_sentences):\n",
        "  if len(sent) >= min_sentence_length:\n",
        "    purged_sentences.append([w if w in word_to_index else unknown_token for w in sent[0:truncate_sentence_length]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r09ZMRxqk7pC",
        "colab_type": "code",
        "outputId": "3d41f3d2-19bf-4840-8be9-ab20671b64e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(\"Purged %d sentences.\" % (len(purged_sentences)))\n",
        "for i in range(0, 10):\n",
        "  print(\"Example: %s\" % purged_sentences[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Purged 11872 sentences.\n",
            "Example: ['SENTENCE_START', 'story', 'of', 'a', 'man', 'who', 'has', 'UNKNOWN_TOKEN', 'UNKNOWN_TOKEN', 'for']\n",
            "Example: ['SENTENCE_START', 'starts', 'out', 'with', 'a', 'opening', 'scene', 'that', 'is', 'a']\n",
            "Example: ['SENTENCE_START', 'a', 'UNKNOWN_TOKEN', 'UNKNOWN_TOKEN', 'audience', 'is', 'turned', 'into', 'an', 'UNKNOWN_TOKEN']\n",
            "Example: ['SENTENCE_START', 'unfortunately', 'it', 'UNKNOWN_TOKEN', 'absurd', 'the', 'whole', 'time', 'with', 'no']\n",
            "Example: ['SENTENCE_START', 'even', 'those', 'from', 'the', 'UNKNOWN_TOKEN', 'should', 'be', 'turned', 'off']\n",
            "Example: ['SENTENCE_START', 'the', 'UNKNOWN_TOKEN', 'dialogue', 'would', 'make', 'UNKNOWN_TOKEN', 'seem', 'UNKNOWN_TOKEN', 'to']\n",
            "Example: ['SENTENCE_START', 'on', 'a', 'UNKNOWN_TOKEN', 'level', 'it', \"'s\", 'better', 'than', 'you']\n",
            "Example: ['SENTENCE_START', 'future', 'stars', 'UNKNOWN_TOKEN', 'UNKNOWN_TOKEN', 'and', 'UNKNOWN_TOKEN', 'UNKNOWN_TOKEN', 'can', 'be']\n",
            "Example: ['SENTENCE_START', 'airport', 'UNKNOWN_TOKEN', 'starts', 'as', 'a', 'UNKNOWN_TOKEN', 'new', 'UNKNOWN_TOKEN', 'UNKNOWN_TOKEN']\n",
            "Example: ['SENTENCE_START', 'the', 'UNKNOWN_TOKEN', 'UNKNOWN_TOKEN', 'takes', 'off', 'as', 'UNKNOWN_TOKEN', 'but', 'UNKNOWN_TOKEN']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx-hXzf4_8g1",
        "colab_type": "text"
      },
      "source": [
        "Create the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnTX5tex_zg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.asarray([[word_to_index[w] for w in sent[:-1]] for sent in purged_sentences])\n",
        "Y_train = np.asarray([[word_to_index[w] for w in sent[1:]] for sent in purged_sentences])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUwaGdwHIBtc",
        "colab_type": "code",
        "outputId": "9c98b834-4727-4270-ba8f-8c27da0d5e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Example: \", X_train[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example:  [1, 4, 999, 999, 278, 8, 465, 99, 43]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpzQxszlDOYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "    xt = np.exp(x - np.max(x))\n",
        "    return xt / np.sum(xt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yr2h159_7F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN:\n",
        "    \n",
        "  def __init__(self, word_dim, hidden_dim=100):\n",
        "      # Assign instance variables\n",
        "      self.word_dim = word_dim\n",
        "      self.hidden_dim = hidden_dim\n",
        "      # Randomly initialize the network parameters\n",
        "      self.U = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (word_dim, hidden_dim))\n",
        "      self.V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, word_dim))\n",
        "      self.W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, hidden_dim))\n",
        "      self.b = np.zeros(hidden_dim)\n",
        "      self.c = np.zeros(word_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Do a forward pass for single example\n",
        "    T = len(x)\n",
        "    h = np.zeros((T , self.hidden_dim))\n",
        "    o = np.zeros((T, self.word_dim))\n",
        "    for t in range(T):\n",
        "      # Note that we are indexing U by x[t]. This is the same as multiplying U with a one-hot vector.\n",
        "      h[t] = self.U[x[t], :] + self.b\n",
        "      if t > 1:\n",
        "        h[t] += np.matmul(self.W.T, h[t-1])\n",
        "      h[t] = np.tanh(h[t])\n",
        "      o[t] = softmax(np.matmul(self.V.T, h[t]) + self.c)\n",
        "    return (o, h)\n",
        "\n",
        "  def backward(self, x, y, clip_value=None):\n",
        "    #Do a backward pass for single example\n",
        "    T = len(x)\n",
        "    o, h = self.forward(x)\n",
        "    # Accumulate the gradients in these variables\n",
        "    dLdU = np.zeros(self.U.shape)\n",
        "    dLdV = np.zeros(self.V.shape)\n",
        "    dLdW = np.zeros(self.W.shape)\n",
        "    dLdb = np.zeros(self.b.shape)\n",
        "    dLdc = np.zeros(self.c.shape)\n",
        "    # dL/do\n",
        "    delta_o = o\n",
        "    delta_o[np.arange(len(y)), y] -= 1.\n",
        "    # dL/dh\n",
        "    delta_h = np.zeros((T, self.hidden_dim))\n",
        "    for t in reversed(range(T)):\n",
        "      delta_h[t] = np.matmul(self.V, delta_o[t, :])\n",
        "      if t < T - 1:\n",
        "        delta_h[t] += np.matmul(np.matmul(self.W, np.diag(1 - h[t+1]**2)), delta_h[t+1])\n",
        "    # Accumulate gradients over time-steps\n",
        "    for t in range(T):\n",
        "      dLdc += delta_o[t, :]\n",
        "      dLdb += (1 - h[t]**2) * delta_h[t, :]\n",
        "      dLdV += np.outer(h[t, :], delta_o[t, :])\n",
        "      if t > 0:\n",
        "        dLdW += np.matmul(np.outer(h[t-1, :], delta_h[t, :]), np.diag(1 - h[t]**2))\n",
        "      xm = np.zeros((self.word_dim))\n",
        "      xm[x] = 1.\n",
        "      dLdU += np.matmul(np.outer(xm, delta_h[t, :]), np.diag(1 - h[t]**2))\n",
        "    if clip_value is not None:\n",
        "      dLdb = np.clip(dLdb, -clip_value, clip_value)\n",
        "      dLdc = np.clip(dLdc, -clip_value, clip_value)\n",
        "      dLdV = np.clip(dLdV, -clip_value, clip_value)\n",
        "      dLdW = np.clip(dLdW, -clip_value, clip_value)\n",
        "      dLdU = np.clip(dLdU, -clip_value, clip_value)\n",
        "    return (dLdU, dLdV, dLdW, dLdb, dLdc)\n",
        "\n",
        "  def step(self, x, y, learning_rate=0.01):\n",
        "    # Perform SGD step for single example\n",
        "    dLdU, dLdV, dLdW, dLdb, dLdc  = self.backward(x, y)\n",
        "    self.U -= learning_rate * dLdU\n",
        "    self.V -= learning_rate * dLdV\n",
        "    self.W -= learning_rate * dLdW\n",
        "    self.b -= learning_rate * dLdb\n",
        "    self.c -= learning_rate * dLdc\n",
        "\n",
        "  def loss(self, x, y):\n",
        "    # Per example loss\n",
        "    o, h = self.forward(x)\n",
        "    return - np.sum(o[np.arange(len(y)), y])\n",
        "\n",
        "  def generate_sentence(self, max_length=20):\n",
        "    # We start the sentence with the start token\n",
        "    new_sentence = [word_to_index[sentence_start_token]]\n",
        "    # Repeat until we get an end token or reach maximum sentence length\n",
        "    while not new_sentence[-1] == word_to_index[sentence_end_token] and len(new_sentence) < max_length:\n",
        "      o, h = self.forward(new_sentence)\n",
        "      sampled_word = word_to_index[unknown_token]\n",
        "      # We don't want to sample unknown words or sentence start\n",
        "      while sampled_word == word_to_index[unknown_token] or sampled_word == word_to_index[sentence_start_token]:\n",
        "          samples = np.random.multinomial(1, o[-1])\n",
        "          sampled_word = np.argmax(samples)\n",
        "      new_sentence.append(sampled_word)\n",
        "    sentence_str = [index_to_word[x] for x in new_sentence]\n",
        "    return sentence_str\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRw6_OG4CNt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNN(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbYNOpEQM7sI",
        "colab_type": "text"
      },
      "source": [
        "Generate random sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UI5anlSCSxe",
        "colab_type": "code",
        "outputId": "76d6ab80-08ad-49ab-f44f-25deb92d9e09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "for i in range(10):\n",
        "  print(model.generate_sentence())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['SENTENCE_START', 'viewers', 'business', 'been', 'credits', 'may', 'which', 'happened', 'wanted', 'keep', 'days', 'cool', 'woody', 'spent', 'during', \"'re\", 'yourself', 'ends', 'anil', 'somehow']\n",
            "['SENTENCE_START', 'must', 'watched', 'people', 'monster', 'cut', 'simply', 'viewers', 'version', 'guys', 'managed', 'down', 'does', 'badly', 'far', 'lame', 'anything', 'horrible', 'during', 'making']\n",
            "['SENTENCE_START', 'blame', 'forget', 'appear', 'woody', 'huge', 'our', 'another', 'before', 'van', 'line', 'liked', 'van', 'three', 'job', 'minutes', 'may', 'off', 'much', 'total']\n",
            "['SENTENCE_START', 'entertaining', 'parts', 'among', 'pointless', 'most', 'romance', \"''\", 'points', 'll', 'change', 'cast', 'deserves', 'air', 'done', 'bring', 'write', 'you', 'performances', 'saying']\n",
            "['SENTENCE_START', 'freeman', 'stick', 'stories', 'my', 'ca', 'possibly', 'through', 'few', 'completely', 'easily', 'will', 'tone', 'sorry', 'your', 'moment', 'viewing', 'funny', 'gore', 'show']\n",
            "['SENTENCE_START', 'j', 'full', 'ask', 'way', 'between', 'hours', 'laughable', 'slow', 'thats', 'went', 'moment', 'avoid', 'work', 'favorite', 'production', 'zero', 'laughed', 'video', 'akshay']\n",
            "['SENTENCE_START', 'for', 'j', 'movie', 'cinema', 'biggest', 'freeman', 'happy', 'beautiful', 'was', 'yet', 'knows', 'takes', '``', 'bergman', 'them', 'ago', 'simply', 'bar', 'killed']\n",
            "['SENTENCE_START', 'business', 'doing', 'job', 'airport', 'half', 'happy', 'wo', 'full', 'piece', 'class', 'road', 'actress', 'romance', 'unbelievable', 'budget', 'level', 'sister', 'nothing', 'imdb']\n",
            "['SENTENCE_START', 'forced', 'tells', 'goes', 'leading', 'tell', 'hit', 'viewing', 'utterly', 'different', 'oh', 'thats', 'tries', 'sequences', 'name', 'jokes', 'went', 'kill', 'rest', 'a']\n",
            "['SENTENCE_START', 'problem', 'of', 'fine', 'slow', 'not', 'go', 'acted', 'unbelievable', 'their', 'copy', 'damme', 'against', 'act', 'thought', 'going', 'acharya', 'wish', 'dead', 'victor']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDAjHknvCb7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 100\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WG1piZGyUHw",
        "colab_type": "text"
      },
      "source": [
        "Limit training examples to save time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5umSeVdByQTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train[0:1000]\n",
        "Y_train = Y_train[0:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcVe2NKPZlk5",
        "colab_type": "code",
        "outputId": "46ab48ec-36fa-480c-d255-7b401d201bae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loss_history = []\n",
        "for epoch in range(num_epochs):\n",
        "  loss = 0\n",
        "  for i in range(len(X_train)):\n",
        "    loss += model.loss(X_train[i], Y_train[i])\n",
        "  loss = loss / len(X_train)\n",
        "  print(\"Epoch {0} Loss {1}\".format(epoch , loss))\n",
        "  loss_history.append(loss)\n",
        "  for i in range(len(X_train)):\n",
        "    model.step(X_train[i], Y_train[i], learning_rate=learning_rate)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Loss -0.008668172033746894\n",
            "Epoch 1 Loss -0.3035566640598766\n",
            "Epoch 2 Loss -0.3109876940214069\n",
            "Epoch 3 Loss -0.31649287654410385\n",
            "Epoch 4 Loss -0.317805586879245\n",
            "Epoch 5 Loss -0.32304793363724726\n",
            "Epoch 6 Loss -0.3298925390021522\n",
            "Epoch 7 Loss -0.3222189754016794\n",
            "Epoch 8 Loss -0.33530723620817166\n",
            "Epoch 9 Loss -0.33488791546577856\n",
            "Epoch 10 Loss -0.3401277414491794\n",
            "Epoch 11 Loss -0.3449910054890074\n",
            "Epoch 12 Loss -0.34140817727845263\n",
            "Epoch 13 Loss -0.34750909296908616\n",
            "Epoch 14 Loss -0.34592549631554775\n",
            "Epoch 15 Loss -0.3344905126089125\n",
            "Epoch 16 Loss -0.3408553071678734\n",
            "Epoch 17 Loss -0.34815788208542725\n",
            "Epoch 18 Loss -0.3445132892243871\n",
            "Epoch 19 Loss -0.32013053215923426\n",
            "Epoch 20 Loss -0.3436545508345637\n",
            "Epoch 21 Loss -0.3492189133850266\n",
            "Epoch 22 Loss -0.3417025987418145\n",
            "Epoch 23 Loss -0.34575514477047875\n",
            "Epoch 24 Loss -0.34670889394400695\n",
            "Epoch 25 Loss -0.361193242097213\n",
            "Epoch 26 Loss -0.3565473734784901\n",
            "Epoch 27 Loss -0.3562844570132202\n",
            "Epoch 28 Loss -0.35852741157824336\n",
            "Epoch 29 Loss -0.36402550616116836\n",
            "Epoch 30 Loss -0.3621267984723609\n",
            "Epoch 31 Loss -0.36986935851292524\n",
            "Epoch 32 Loss -0.35874586282734283\n",
            "Epoch 33 Loss -0.38283460784903\n",
            "Epoch 34 Loss -0.3780830073414612\n",
            "Epoch 35 Loss -0.3826223185719585\n",
            "Epoch 36 Loss -0.37779295423069603\n",
            "Epoch 37 Loss -0.3799528750679177\n",
            "Epoch 38 Loss -0.37850490093874833\n",
            "Epoch 39 Loss -0.3944590139719208\n",
            "Epoch 40 Loss -0.3570628521432847\n",
            "Epoch 41 Loss -0.3783251296892081\n",
            "Epoch 42 Loss -0.37052000861106704\n",
            "Epoch 43 Loss -0.36664562347770924\n",
            "Epoch 44 Loss -0.3861051972552214\n",
            "Epoch 45 Loss -0.3814940276223924\n",
            "Epoch 46 Loss -0.37832916382810455\n",
            "Epoch 47 Loss -0.37257992026275044\n",
            "Epoch 48 Loss -0.3803322775500622\n",
            "Epoch 49 Loss -0.3796629816890891\n",
            "Epoch 50 Loss -0.3886797630261079\n",
            "Epoch 51 Loss -0.3961172316693929\n",
            "Epoch 52 Loss -0.4008391440353702\n",
            "Epoch 53 Loss -0.3934099314498988\n",
            "Epoch 54 Loss -0.40177830732675124\n",
            "Epoch 55 Loss -0.39423372684981306\n",
            "Epoch 56 Loss -0.4003808710898938\n",
            "Epoch 57 Loss -0.38841362153037207\n",
            "Epoch 58 Loss -0.4010736151388749\n",
            "Epoch 59 Loss -0.3966620785874534\n",
            "Epoch 60 Loss -0.3886462449204268\n",
            "Epoch 61 Loss -0.4131578479650738\n",
            "Epoch 62 Loss -0.39840321780395604\n",
            "Epoch 63 Loss -0.42736439834149986\n",
            "Epoch 64 Loss -0.4164913379795316\n",
            "Epoch 65 Loss -0.4089225652881779\n",
            "Epoch 66 Loss -0.4269985200151251\n",
            "Epoch 67 Loss -0.4008136959508633\n",
            "Epoch 68 Loss -0.4000959867872007\n",
            "Epoch 69 Loss -0.402183483173679\n",
            "Epoch 70 Loss -0.3987274777695473\n",
            "Epoch 71 Loss -0.40517136947710203\n",
            "Epoch 72 Loss -0.42326922117370747\n",
            "Epoch 73 Loss -0.4130055435501495\n",
            "Epoch 74 Loss -0.4156171347331734\n",
            "Epoch 75 Loss -0.40012350326481794\n",
            "Epoch 76 Loss -0.4145421621744176\n",
            "Epoch 77 Loss -0.4201112817818142\n",
            "Epoch 78 Loss -0.41313606804463376\n",
            "Epoch 79 Loss -0.414949492349271\n",
            "Epoch 80 Loss -0.414403347510198\n",
            "Epoch 81 Loss -0.396644725203052\n",
            "Epoch 82 Loss -0.4263465448270256\n",
            "Epoch 83 Loss -0.406665238643091\n",
            "Epoch 84 Loss -0.4121571730697685\n",
            "Epoch 85 Loss -0.4148122297896746\n",
            "Epoch 86 Loss -0.4418184447873209\n",
            "Epoch 87 Loss -0.44020542292293396\n",
            "Epoch 88 Loss -0.4189958599064142\n",
            "Epoch 89 Loss -0.43118044477745193\n",
            "Epoch 90 Loss -0.4128448448450982\n",
            "Epoch 91 Loss -0.4013857768528097\n",
            "Epoch 92 Loss -0.4287421708162608\n",
            "Epoch 93 Loss -0.4204420281150371\n",
            "Epoch 94 Loss -0.42896334063071145\n",
            "Epoch 95 Loss -0.42505307523736885\n",
            "Epoch 96 Loss -0.4231264261110717\n",
            "Epoch 97 Loss -0.41818072929374694\n",
            "Epoch 98 Loss -0.40566844620019116\n",
            "Epoch 99 Loss -0.4126093456482267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lGGVmE3hkMg",
        "colab_type": "code",
        "outputId": "14c44e9f-afb8-49f0-ccd9-c3073c231fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "ax = plt.subplot(1, 1, 1)\n",
        "ax.plot(loss_history[:])\n",
        "ax.set_xlabel('Epoch', fontsize=14)\n",
        "ax.set_ylabel('Loss', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAGoCAYAAAATsnHAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmpzCd6-KMru",
        "colab_type": "code",
        "outputId": "7a054ea2-7f55-422e-9be6-7fb06a16618e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for i in range(10):\n",
        "  print(model.generate_sentence())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['SENTENCE_START', 'song', 'comes', 'course', 'you', 'many', 'get', 'would', 'as', 'sure', 'a', 'could', 'to', 'this', 'the', 'for', 'movies', 'their', 'be', 'movie']\n",
            "['SENTENCE_START', 'so', 'i', 'got', \"'ve\", 'would', 'without', 'would', 'knew', 'or', 'a', 'SENTENCE_END']\n",
            "['SENTENCE_START', 'a', 'movie', 'first', 'seem', ',', 'were', 'and', 'original', 'and', 'in', 'first', 'who', 'of', 'were', 'after', 'he', 'is', 'a', 'is']\n",
            "['SENTENCE_START', 'getting', 'it', 'has', 'be', 'husband', 'to', 'few', 'without', 'that', '``', ')', 'the', 'i', 'and', 'for', 'edison', 'movie', 'watch', 'been']\n",
            "['SENTENCE_START', 'everyone', 'zero', 'i', 'was', 'this', 'write', 'grease', 'audience', 'the', 'audience', 'it', 'left', 'be', 'SENTENCE_END']\n",
            "['SENTENCE_START', 'if', 'he', 'effort', 'out', 'fire', 'which', 'i', 'am', 'hit', 'its', 'it', 'how', 'write', 'you', 'been', \"'m\", 'than', 'a', 'on']\n",
            "['SENTENCE_START', 'this', 'it', 'has', 'a', 'is', 'man', 'few', 'time', 'movie', 'written', 'miss', 'and', 'it', 'the', 'the', 'most', 'ca', 'to', 'this']\n",
            "['SENTENCE_START', 'starts', 'this', 'it', 'in', 'future', 'to', 'to', 'and', 'got', 'but', 'and', 'who', 'the', 'a', 'it', 'that', 'the', 'two', 'school']\n",
            "['SENTENCE_START', 'i', 'felt', 'painful', 'looking', 'but', 'we', 'this', \"'ve\", 'talk', 'a', 'been', 'make', 'go', 'in', 'that', 'even', 'SENTENCE_END']\n",
            "['SENTENCE_START', 'you', 'you', 'do', 'a', 'akshay', 'looking', 'made', 'a', 'are', 'as', 'feel', 'left', 'this', 'donner', 'be', 'the', 'film', 'in', 'the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D16DIBo1Kbep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}