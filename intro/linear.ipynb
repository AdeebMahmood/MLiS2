{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrirYYWnJGuS34GhT9BdBW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adammoss/MLiS2/blob/master/intro/linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VvAxo8-piUE4"
      },
      "source": [
        "The simplest type of neural network is the linear model, which maps an input vector to a scalar output by \n",
        "$\n",
        "\\hat{y} = \\mathbf{x}^T \\mathbf{w} \\,.\n",
        "$\n",
        "\n",
        "Let us see how the linear model performs on two simple problems: learning the AND and XOR (exclusive OR) functions. The AND function is an operation on two binary values, $x_1$ and $x_2$, which is equal to 1 when $x_1=x_2=1$ and 0 otherwise. The inputs and targets are then  (with the first column of $\\mathbf{X}$ all ones)\n",
        "\n",
        "\n",
        "$\n",
        "\\mathbf{X} = \\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "1 & 0 & 1  \\\\\n",
        "1& 1 & 0 \\\\\n",
        "1 & 1 & 1 \n",
        "\\end{bmatrix}\\,, \\quad \\mathbf{Y} = \\begin{bmatrix}\n",
        "0 \\\\\n",
        "0  \\\\\n",
        "0 \\\\ \n",
        "1  \n",
        "\\end{bmatrix}\\,.\n",
        "$\n",
        "\n",
        "For the XOR problem, when exactly one of $x_1$ or $x_2$ is equal to 1 it returns 1, otherwise it returns 0. The inputs and targets are then \n",
        "\n",
        "$\n",
        "\\mathbf{X} = \\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "1 & 0 & 1  \\\\\n",
        "1& 1 & 0 \\\\\n",
        "1 & 1 & 1 \n",
        "\\end{bmatrix}\\,, \\quad \\mathbf{Y} = \\begin{bmatrix}\n",
        "0 \\\\\n",
        "1  \\\\\n",
        "1 \\\\ \n",
        "0  \n",
        "\\end{bmatrix}\\,.\n",
        "$\n",
        "\n",
        "We choose to model this as a regression problem and so use the MSE loss. In reality, when dealing with binary data, the BCE is usually more appropriate, but using the MSE simplifies the maths. The loss is then\n",
        "\n",
        "$\n",
        " L  (\\mathbf{w}) = \\frac{1}{4} \\left( \\mathbf{X} \\mathbf{w} -   \\mathbf{Y}  \\right)^T \\left( \\mathbf{X} \\mathbf{w} -   \\mathbf{Y}  \\right)\\,.\n",
        " $\n",
        "\n",
        " The optimal weights can be found by calculating the gradient of the loss and solving for when it is $\\mathbf{0}$\n",
        "\n",
        "$\n",
        " \\nabla_{\\mathbf{w}}  L  (\\mathbf{w})  = 2 \\mathbf{X}^T \\mathbf{X} \\mathbf{w} - 2 \\mathbf{X}^T \\mathbf{Y} = \\mathbf{0}\\,,\n",
        "$\n",
        "\n",
        " which gives the solution $\\mathbf{w}  = \\left( \\mathbf{X}^T \\mathbf{X} \\right)^{-1}  \\mathbf{X}^T \\mathbf{Y}$. \n",
        " \n",
        " For the AND problem, the optimal weights and prediction vector are\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU0UBNf2iY9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SN2nLTDdiTmv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "472e58d1-d211-42ba-e130-cc0be7de0dc5"
      },
      "source": [
        "X = np.array([[1,0,0], [1,0,1], [1,1,0], [1,1,1]])\n",
        "print(X)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 0]\n",
            " [1 0 1]\n",
            " [1 1 0]\n",
            " [1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjqnS8oHhIFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inv = np.linalg.inv(np.matmul(X.T, X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSpvpo1shGzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = np.array([[0], [0], [0], [1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqkP-Tm_g34R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e1d82428-1b5c-4e08-9e71-879fe785b9f0"
      },
      "source": [
        "w = np.matmul(inv,  np.matmul(X.T, Y))\n",
        "print(w)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.25]\n",
            " [ 0.5 ]\n",
            " [ 0.5 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AokmboQPg8cZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b2f65dd2-de7f-4b41-e897-9d97dd967c5a"
      },
      "source": [
        "Yhat = np.matmul(X, w)\n",
        "print(Yhat)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.25]\n",
            " [ 0.25]\n",
            " [ 0.25]\n",
            " [ 0.75]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxja-NcDlmPd",
        "colab_type": "text"
      },
      "source": [
        "For the XOR problem, the optimal weights and prediction vector are"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ycubNISlokQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = np.array([[0], [1], [1], [0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI89H99LlrZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "954e86ae-04fa-4cd9-b3ab-b48db7a9fd6d"
      },
      "source": [
        "w = np.matmul(inv,  np.matmul(X.T, Y))\n",
        "print(w)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5]\n",
            " [0. ]\n",
            " [0. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz3l5C_-l5nz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0b2d71ee-65be-4271-e935-5d37a0fefef4"
      },
      "source": [
        "Yhat = np.matmul(X, w)\n",
        "print(Yhat)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}