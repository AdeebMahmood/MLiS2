{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6VKYhwCWNzzvqkuuWwl0R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adammoss/MLiS2/blob/master/intro/linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VvAxo8-piUE4"
      },
      "source": [
        "The simplest type of neural network is the linear model, which maps an input vector to a scalar output by \n",
        "\n",
        "$\n",
        "\\hat{y} = \\mathbf{x}^T \\mathbf{w} \\,.\n",
        "$\n",
        "\n",
        "Computationally it is more efficient to pass through an entire batch of inputs, in which case \n",
        "\n",
        "$\n",
        "\\hat{\\mathbf{Y}} = \\mathbf{X} \\mathbf{w} \\,.\n",
        "$\n",
        "\n",
        "Let us see how the linear model performs on two simple problems: learning the AND and XOR (exclusive OR) functions. The AND function is an operation on two binary values, $x_1$ and $x_2$, which is equal to 1 when $x_1=x_2=1$ and 0 otherwise. The inputs and targets are then  (with the first column of $\\mathbf{X}$ all ones)\n",
        "\n",
        "\n",
        "$\n",
        "\\mathbf{X} = \\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "1 & 0 & 1  \\\\\n",
        "1& 1 & 0 \\\\\n",
        "1 & 1 & 1 \n",
        "\\end{bmatrix}\\,, \\quad \\mathbf{Y} = \\begin{bmatrix}\n",
        "0 \\\\\n",
        "0  \\\\\n",
        "0 \\\\ \n",
        "1  \n",
        "\\end{bmatrix}\\,.\n",
        "$\n",
        "\n",
        "For the XOR problem, when exactly one of $x_1$ or $x_2$ is equal to 1 it returns 1, otherwise it returns 0. The inputs and targets are then \n",
        "\n",
        "$\n",
        "\\mathbf{X} = \\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "1 & 0 & 1  \\\\\n",
        "1& 1 & 0 \\\\\n",
        "1 & 1 & 1 \n",
        "\\end{bmatrix}\\,, \\quad \\mathbf{Y} = \\begin{bmatrix}\n",
        "0 \\\\\n",
        "1  \\\\\n",
        "1 \\\\ \n",
        "0  \n",
        "\\end{bmatrix}\\,.\n",
        "$\n",
        "\n",
        "We choose to model this as a regression problem and so use the MSE loss. In reality, when dealing with binary data, the BCE is usually more appropriate, but using the MSE simplifies the maths. The loss is then\n",
        "\n",
        "$\n",
        " L  (\\mathbf{w}) = \\frac{1}{4} \\left( \\mathbf{X} \\mathbf{w} -   \\mathbf{Y}  \\right)^T \\left( \\mathbf{X} \\mathbf{w} -   \\mathbf{Y}  \\right)\\,.\n",
        " $\n",
        "\n",
        " The optimal weights can be found by calculating the gradient of the loss and solving the normal equations\n",
        "\n",
        "$\n",
        " \\nabla_{\\mathbf{w}}  L  (\\mathbf{w})  = 2 \\mathbf{X}^T \\mathbf{X} \\mathbf{w} - 2 \\mathbf{X}^T \\mathbf{Y} = \\mathbf{0}\\,,\n",
        "$\n",
        "\n",
        " which gives the solution $\\mathbf{w}  = \\left( \\mathbf{X}^T \\mathbf{X} \\right)^{-1}  \\mathbf{X}^T \\mathbf{Y}$. \n",
        " \n",
        "Let us first attempt to learn the AND function.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU0UBNf2iY9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SN2nLTDdiTmv",
        "outputId": "804583a2-471d-42d2-ad71-12d874503a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "X = np.array([[1,0,0], [1,0,1], [1,1,0], [1,1,1]])\n",
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 0]\n",
            " [1 0 1]\n",
            " [1 1 0]\n",
            " [1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjqnS8oHhIFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inv = np.linalg.inv(np.matmul(X.T, X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSpvpo1shGzu",
        "colab_type": "code",
        "outputId": "22d3ca52-11f4-4d37-c2c6-17004d460913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "Y = np.array([[0], [0], [0], [1]])\n",
        "print(Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqkP-Tm_g34R",
        "colab_type": "code",
        "outputId": "ceb5465b-70e3-43ca-ab54-acd320bc55eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "w = np.matmul(inv,  np.matmul(X.T, Y))\n",
        "print(w)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.25]\n",
            " [ 0.5 ]\n",
            " [ 0.5 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AokmboQPg8cZ",
        "colab_type": "code",
        "outputId": "9ce27529-4c33-4dd0-9dd4-f41bca88da6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "Yhat = np.matmul(X, w)\n",
        "print(Yhat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.25]\n",
            " [ 0.25]\n",
            " [ 0.25]\n",
            " [ 0.75]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxja-NcDlmPd",
        "colab_type": "text"
      },
      "source": [
        "Now let us attempt to learn the XOR function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ycubNISlokQ",
        "colab_type": "code",
        "outputId": "8526533d-9ef3-4f04-e9b5-6bbad5c89965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "Y = np.array([[0], [1], [1], [0]])\n",
        "print(Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI89H99LlrZD",
        "colab_type": "code",
        "outputId": "5b2d14be-42f6-43d7-d4ca-93b0862a0ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "w = np.matmul(inv,  np.matmul(X.T, Y))\n",
        "print(w)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5]\n",
            " [0. ]\n",
            " [0. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz3l5C_-l5nz",
        "colab_type": "code",
        "outputId": "1e3dbbc2-456f-4f16-9a66-ebf7461a9a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "Yhat = np.matmul(X, w)\n",
        "print(Yhat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "528QTK744D-m",
        "colab_type": "text"
      },
      "source": [
        "The linear model completely fails to represent the XOR function, outputting 1/2 for all examples."
      ]
    }
  ]
}