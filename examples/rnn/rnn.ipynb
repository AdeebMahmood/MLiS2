{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdVHefQ2qOrAtS9O/83D8a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adammoss/MLiS2/blob/master/examples/rnn/rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alq1W_bCWoTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import itertools\n",
        "import operator\n",
        "import numpy as np\n",
        "import nltk\n",
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhl7G_SQ7wlH",
        "colab_type": "text"
      },
      "source": [
        "Download NLTK data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRyc8euxWpzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "nltk.download(\"book\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBvLWBQt8EZ6",
        "colab_type": "text"
      },
      "source": [
        "Upload deep_learning_sentences.txt file (or another file containing a list of sentences if you wish)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfpGBFRj-DzH",
        "colab_type": "code",
        "outputId": "ce6a9456-8a0e-4ed5-e43f-7bf613b394d1",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3ac82561-3b02-4465-ba2c-35231e8806a2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3ac82561-3b02-4465-ba2c-35231e8806a2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving deep_learning_sentences.txt to deep_learning_sentences (1).txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHNYmTqB93G9",
        "colab_type": "text"
      },
      "source": [
        "Add sentence start and end tags, convert to lower case and strip newlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyBM3rWv9chG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_start_token = \"SENTENCE_START\"\n",
        "sentence_end_token = \"SENTENCE_END\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8QVY1IkAYEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('deep_learning_sentences.txt', 'r') as f:\n",
        "  sentences = f.readlines()\n",
        "sentences = [\"%s %s %s\" % (sentence_start_token, x.lstrip().rstrip('.\\n').lower(), sentence_end_token) for x in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPIWW5lqtSLG",
        "colab_type": "code",
        "outputId": "a08da560-f0a6-4b08-8345-52f8682689f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "print(\"Parsed %d sentences.\" % (len(sentences)))\n",
        "for i in range(0, 10):\n",
        "  print(\"Example: %s\" % sentences[i])"
      ],
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsed 7674 sentences.\n",
            "Example: SENTENCE_START part ii  deep networks: modern  practices  166    this part of the book summarizes the state of modern deep learning as it is used to solve practical applications SENTENCE_END\n",
            "Example: SENTENCE_START this part focuses only on those approaches that are essentially working tech- nologies that are already used heavily in industry SENTENCE_END\n",
            "Example: SENTENCE_START by adding more layers and more units within a layer, a deep network can represent functions of increasing complexity SENTENCE_END\n",
            "Example: SENTENCE_START most tasks that consist of mapping an input vector to an output vector, and that are easy for a person to do rapidly, can be accomplished via deep learning, given sufficiently large models and sufficiently large datasets of labeled training examples SENTENCE_END\n",
            "Example: SENTENCE_START other tasks, that can not be described as associating one vector to another, or that are difficult enough that a person would require time to think and reflect in order to accomplish the task, remain beyond the scope of deep learning for now SENTENCE_END\n",
            "Example: SENTENCE_START this part of the book describes the core parametric function approximation technology that is behind nearly all modern practical applications of deep learning SENTENCE_END\n",
            "Example: SENTENCE_START scaling these models to large inputs such as high resolution images or long temporal sequences requires specialization SENTENCE_END\n",
            "Example: SENTENCE_START we introduce the convolutional network for scaling to large images and the recurrent neural network for processing temporal sequences SENTENCE_END\n",
            "Example: SENTENCE_START finally, we present general guidelines for the practical methodology involved in designing, building, and configuring an application involving deep learning, and review some of the applications of deep learning SENTENCE_END\n",
            "Example: SENTENCE_START these chapters are the most important for a practitioner—someone who wants to begin implementing and using deep learning algorithms to solve real-world  problems today SENTENCE_END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTBDO_fs-udT",
        "colab_type": "text"
      },
      "source": [
        "Tokenize the sentences into words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRfoIQZV-tNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDJ1NGJy-7i_",
        "colab_type": "code",
        "outputId": "6bd56d39-ad59-43c9-e1aa-163c031feeef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
        "print(\"Found %d unique words tokens.\" % len(word_freq.items()))"
      ],
      "execution_count": 471,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13509 unique words tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZGpHm2s_IyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 1000\n",
        "unknown_token = 'UNKNOWN_TOKEN'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBTJmo8G_Fv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = word_freq.most_common(vocab_size-1)\n",
        "index_to_word = [x[0] for x in vocab]\n",
        "index_to_word.append(unknown_token)\n",
        "word_to_index = dict([(w,i) for i, w in enumerate(index_to_word)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-C-wm5h_kQB",
        "colab_type": "text"
      },
      "source": [
        "Replace all words not in our vocabulary with the unknown token and discard sentences under min / over max number of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS0xWviykoTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_sentence_length = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXT2EKyw_h6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "purged_sentences = []\n",
        "for i, sent in enumerate(tokenized_sentences):\n",
        "    purged_sentences.append([w if w in word_to_index else unknown_token for w in sent[0:max_sentence_length]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r09ZMRxqk7pC",
        "colab_type": "code",
        "outputId": "2b8def32-613e-426e-b0e3-5e87a57f9d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(\"Purged %d sentences.\" % (len(purged_sentences)))\n",
        "for i in range(0, 10):\n",
        "  print(\"Example: %s\" % purged_sentences[i])"
      ],
      "execution_count": 478,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Purged 7674 sentences.\n",
            "Example: ['SENTENCE_START', 'part', 'UNKNOWN_TOKEN', 'deep']\n",
            "Example: ['SENTENCE_START', 'this', 'part', 'UNKNOWN_TOKEN']\n",
            "Example: ['SENTENCE_START', 'by', 'adding', 'more']\n",
            "Example: ['SENTENCE_START', 'most', 'tasks', 'that']\n",
            "Example: ['SENTENCE_START', 'other', 'tasks', ',']\n",
            "Example: ['SENTENCE_START', 'this', 'part', 'of']\n",
            "Example: ['SENTENCE_START', 'scaling', 'these', 'models']\n",
            "Example: ['SENTENCE_START', 'we', 'introduce', 'the']\n",
            "Example: ['SENTENCE_START', 'UNKNOWN_TOKEN', ',', 'we']\n",
            "Example: ['SENTENCE_START', 'these', 'UNKNOWN_TOKEN', 'are']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx-hXzf4_8g1",
        "colab_type": "text"
      },
      "source": [
        "Create the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnTX5tex_zg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.asarray([[word_to_index[w] for w in sent[:-1]] for sent in purged_sentences])\n",
        "Y_train = np.asarray([[word_to_index[w] for w in sent[1:]] for sent in purged_sentences])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUwaGdwHIBtc",
        "colab_type": "code",
        "outputId": "58cd90b2-120f-4556-d1d0-1d9a492f49f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Example: \", X_train[2])"
      ],
      "execution_count": 480,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example:  [  2  22 547]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpzQxszlDOYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "    xt = np.exp(x - np.max(x))\n",
        "    return xt / np.sum(xt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yr2h159_7F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN:\n",
        "    \n",
        "  def __init__(self, word_dim, hidden_dim=100):\n",
        "      # Assign instance variables\n",
        "      self.word_dim = word_dim\n",
        "      self.hidden_dim = hidden_dim\n",
        "      # Randomly initialize the network parameters\n",
        "      self.U = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (word_dim, hidden_dim))\n",
        "      self.V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, word_dim))\n",
        "      self.W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, hidden_dim))\n",
        "      self.b = np.zeros(hidden_dim)\n",
        "      self.c = np.zeros(word_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Do a forward pass for single example\n",
        "    T = len(x)\n",
        "    h = np.zeros((T , self.hidden_dim))\n",
        "    o = np.zeros((T, self.word_dim))\n",
        "    for t in range(T):\n",
        "      # Note that we are indexing U by x[t]. This is the same as multiplying U with a one-hot vector.\n",
        "      h[t] = self.U[x[t], :] + self.b\n",
        "      if t > 1:\n",
        "        h[t] += np.matmul(self.W.T, h[t-1])\n",
        "      o[t] = softmax(np.matmul(self.V.T, h[t]) + self.c)\n",
        "    return (o, h)\n",
        "\n",
        "  def backward(self, x, y, clip_value=None):\n",
        "    #Do a backward pass for single example\n",
        "    T = len(x)\n",
        "    o, h = self.forward(x)\n",
        "    # Accumulate the gradients in these variables\n",
        "    dLdU = np.zeros(self.U.shape)\n",
        "    dLdV = np.zeros(self.V.shape)\n",
        "    dLdW = np.zeros(self.W.shape)\n",
        "    dLdb = np.zeros(self.b.shape)\n",
        "    dLdc = np.zeros(self.c.shape)\n",
        "    # dL/do\n",
        "    delta_o = o\n",
        "    delta_o[np.arange(len(y)), y] -= 1.\n",
        "    # dL/dh\n",
        "    delta_h = np.zeros((T, self.hidden_dim))\n",
        "    for t in reversed(range(T)):\n",
        "      delta_h[t] = np.matmul(self.V, delta_o[t, :])\n",
        "      if t < T - 1:\n",
        "        delta_h[t] += np.matmul(np.matmul(self.W, np.diag(1 - h[t+1]**2)), delta_h[t+1])\n",
        "    # Accumulate gradients over time-steps\n",
        "    for t in range(T):\n",
        "      dLdc += delta_o[t, :]\n",
        "      dLdb += (1 - h[t]**2) * delta_h[t, :]\n",
        "      dLdV += np.outer(h[t, :], delta_o[t, :])\n",
        "      if t > 0:\n",
        "        dLdW += np.matmul(np.outer(h[t-1, :], delta_h[t, :]), np.diag(1 - h[t]**2))\n",
        "      xm = np.zeros((self.word_dim))\n",
        "      xm[x] = 1\n",
        "      dLdW += np.matmul(np.outer(xm, delta_h[t, :]), np.diag(1 - h[t]**2))\n",
        "    if clip_value is not None:\n",
        "      dLdb = np.clip(dLdb, -clip_value, clip_value)\n",
        "      dLdc = np.clip(dLdc, -clip_value, clip_value)\n",
        "      dLdV = np.clip(dLdV, -clip_value, clip_value)\n",
        "      dLdW = np.clip(dLdW, -clip_value, clip_value)\n",
        "      dLdU = np.clip(dLdU, -clip_value, clip_value)\n",
        "    return (dLdU, dLdV, dLdW, dLdb, dLdc)\n",
        "\n",
        "  def step(self, x, y, learning_rate=0.01):\n",
        "    # Perform SGD step for single example\n",
        "    dLdU, dLdV, dLdW, dLdb, dLdc  = self.backward(x, y)\n",
        "    self.U -= learning_rate * dLdU\n",
        "    self.V -= learning_rate * dLdV\n",
        "    self.W -= learning_rate * dLdW\n",
        "    self.b -= learning_rate * dLdb\n",
        "    self.c -= learning_rate * dLdc\n",
        "\n",
        "  def loss(self, x, y):\n",
        "    # Per example loss\n",
        "    o, h = self.forward(x)\n",
        "    return - np.sum(o[np.arange(len(y)), y])\n",
        "\n",
        "  def generate_sentence(self, max_length=20):\n",
        "    # We start the sentence with the start token\n",
        "    new_sentence = [word_to_index[sentence_start_token]]\n",
        "    # Repeat until we get an end token or reach maximum sentence length\n",
        "    while not new_sentence[-1] == word_to_index[sentence_end_token] and len(new_sentence) < max_length:\n",
        "      o, h = self.forward(new_sentence)\n",
        "      sampled_word = word_to_index[unknown_token]\n",
        "      # We don't want to sample unknown words or sentence start\n",
        "      while sampled_word == word_to_index[unknown_token] or sampled_word == word_to_index[sentence_start_token]:\n",
        "          samples = np.random.multinomial(1, o[-1])\n",
        "          sampled_word = np.argmax(samples)\n",
        "      new_sentence.append(sampled_word)\n",
        "    sentence_str = [index_to_word[x] for x in new_sentence]\n",
        "    return sentence_str\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRw6_OG4CNt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNN(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbYNOpEQM7sI",
        "colab_type": "text"
      },
      "source": [
        "Generate random sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UI5anlSCSxe",
        "colab_type": "code",
        "outputId": "581ec4f8-c7be-41a8-dce3-2132d6ea68ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "for i in range(10):\n",
        "  print(model.generate_sentence())"
      ],
      "execution_count": 484,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['SENTENCE_START', 'with', 'sometimes', 'introduction', 'allow', 'negative', 'long', 'form', 'sum', 'during', 'processing', 'taking', 'estimated', 'further', ',', '2015', 'equations', 'dependencies', 'other', 'provide']\n",
            "['SENTENCE_START', 'saddle', 'typical', 'g.', 'further', 'transformation', 'read', 'invariant', 'noise', 'SENTENCE_END']\n",
            "['SENTENCE_START', 'will', 'fewer', 'distribution', 'above', 'we', 'under', 'word', 'just', 'hyperparameter', 'gradients', 'time', 'applying', 'modeling', 'carlo', 'shown', 'xi', 'length', 'predictions', 'few']\n",
            "['SENTENCE_START', 'b', 'minibatch', 'min', 'discrete', 'too', 'pooling', 'appropriate', 'categories', 'images', 'phase', 'xi', 'are', 'around', 'approximately', 'latent', 'stochastic', 'any', 'for', 'nodes']\n",
            "['SENTENCE_START', 'similar', 'within', 'prior', 'convolution', 'interactions', 'generalization', 'gaussian', 'local', 'no', 'arbitrary', 'active', 'arg', 'let', 'perform', '0', 'scale', 'such', 'modes', 'r.']\n",
            "['SENTENCE_START', 'easier', 'z', 'contrast', 'activation', '’', 'covariance', 'same', 'across', 'element', 'units', 'close', 'so', 'tr', 'real', 'specify', 'when', 'applications', 'modeling', 'probabilistic']\n",
            "['SENTENCE_START', 'drawn', 'new', 'model', 'distribution', 'minima', ')', 'determine', 'minimum', 'only', 'from', 'pseudolikelihood', 'size', '2009', 'minimize', 'interesting', 'equivalent', ',', 'increases', 'applied']\n",
            "['SENTENCE_START', 'might', 'forms', '||', 'parametrized', 's.', 'variables', '5', 'cases', 'associated', 'factor', 'next', 'initialize', 'test', 'log', 'still', 'bound', 'weights', 'task', 'variations']\n",
            "['SENTENCE_START', 'describe', 'design', 'when', 'made', 'φ', 'additional', 'arg', 'expected', 'itself', 'ways', 'vectors', 'make', 'o', 'it', 'systems', 'classes', 'density', 'translation', 'end']\n",
            "['SENTENCE_START', 'three', 'amount', 'want', '2011', 'exactly', 'normal', 'speech', 'two', 'scaling', 'like', 'methods', 'significant', 'algorithms', 'design', 'best', 'appropriate', 'works', 'over', 'derivatives']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDAjHknvCb7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 10\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WG1piZGyUHw",
        "colab_type": "text"
      },
      "source": [
        "Limit training examples to save time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5umSeVdByQTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train[0:1000]\n",
        "Y_train = Y_train[0:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcVe2NKPZlk5",
        "colab_type": "code",
        "outputId": "80e78929-ccc8-421b-9a8c-f5d8f776485a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "loss_history = []\n",
        "for epoch in range(num_epochs):\n",
        "  loss = 0\n",
        "  for i in range(len(X_train)):\n",
        "    loss += model.loss(X_train[i], Y_train[i])\n",
        "  loss = loss / len(X_train)\n",
        "  print(\"Epoch {0} Loss {1}\".format(epoch , loss))\n",
        "  loss_history.append(loss)\n",
        "  for i in range(len(X_train)):\n",
        "    model.step(X_train[i], Y_train[i], learning_rate=learning_rate)\n",
        "    \n"
      ],
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Loss -0.0030011303364852965\n",
            "Epoch 1 Loss -0.06315311744466719\n",
            "Epoch 2 Loss -0.06673101399199897\n",
            "Epoch 3 Loss -0.06677437470800422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: overflow encountered in matmul\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in matmul\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: RuntimeWarning: overflow encountered in multiply\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in add\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4 Loss nan\n",
            "Epoch 5 Loss nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-487-3805ed178d6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-482-39a17a597ebc>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, x, y, learning_rate)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Perform SGD step for single example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mdLdU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdLdV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdLdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdLdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdLdc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdLdU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdLdV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-482-39a17a597ebc>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, y, clip_value)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdLdU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdLdV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mdLdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mdLdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdLdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lGGVmE3hkMg",
        "colab_type": "code",
        "outputId": "73457b40-5afa-4f28-f726-37c891d4769d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "ax = plt.subplot(1, 1, 1)\n",
        "ax.plot(loss_history[:])\n",
        "ax.set_xlabel('Epoch', fontsize=14)\n",
        "ax.set_ylabel('Loss', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 488,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAGoCAYAAAATsnHAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmpzCd6-KMru",
        "colab_type": "code",
        "outputId": "cfc3974c-ee8c-4219-f22b-5b27268fab14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "for i in range(10):\n",
        "  print(model.generate_sentence())"
      ],
      "execution_count": 489,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:87: RuntimeWarning: invalid value encountered in greater_equal\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-489-abf7a0685e29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-482-39a17a597ebc>\u001b[0m in \u001b[0;36mgenerate_sentence\u001b[0;34m(self, max_length)\u001b[0m\n\u001b[1;32m     85\u001b[0m       \u001b[0;31m# We don't want to sample unknown words or sentence start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0msampled_word\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munknown_token\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msampled_word\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence_start_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m           \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m           \u001b[0msampled_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0mnew_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.multinomial\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcommon.pyx\u001b[0m in \u001b[0;36mnumpy.random.common.check_array_constraint\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: pvals < 0, pvals > 1 or pvals contains NaNs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D16DIBo1Kbep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}